{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas.io.sql as pd_sql\n",
    "import sqlite3 as sql\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# re-establish database connection\n",
    "con = sql.connect(\"titanic.db\") \n",
    "\n",
    "# extract everything from the 'training_data' table (or whatever you called it) into a dataframe\n",
    "df = pd_sql.read_sql('select * from training_data', con, index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived  Pclass  \\\n",
       "index                                  \n",
       "0                1         0       3   \n",
       "1                2         1       1   \n",
       "2                3         1       3   \n",
       "3                4         1       1   \n",
       "4                5         0       3   \n",
       "\n",
       "                                                    Name     Sex  Age  SibSp  \\\n",
       "index                                                                          \n",
       "0                                Braund, Mr. Owen Harris    male   22      1   \n",
       "1      Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                                 Heikkinen, Miss. Laina  female   26      0   \n",
       "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                               Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "       Parch     Fare Cabin Embarked  \n",
       "index                                 \n",
       "0          0   7.2500  None        S  \n",
       "1          0  71.2833   C85        C  \n",
       "2          0   7.9250  None        S  \n",
       "3          0  53.1000  C123        S  \n",
       "4          0   8.0500  None        S  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Is it all still here?\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by creating a model that predicts purely based on gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of passengers who survived is 0.383838383838.\n"
     ]
    }
   ],
   "source": [
    "# Set some variables\n",
    "number_passengers = df.shape[0] \n",
    "number_survived = len(df[df.Survived == 1])\n",
    "\n",
    "# What proportion of the passengers survived?\n",
    "proportion_survived = float(number_survived) / number_passengers\n",
    "print 'The proportion of passengers who survived is %s.' % proportion_survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of women who survived is 0.742038216561.\n",
      "The proportion of men who survived is 0.188908145581.\n"
     ]
    }
   ],
   "source": [
    "# How can we determine what proportion of the women and of the men who survived?\n",
    "# Let's start by segregating the men and women\n",
    "women = df[df.Sex == \"female\"]\n",
    "men = df[df.Sex != \"female\"]\n",
    "\n",
    "# Determine the proportion of women who survived\n",
    "proportion_women_survived = float(len(women[women.Survived == 1])) / len(women)\n",
    "print 'The proportion of women who survived is %s.' % proportion_women_survived\n",
    "\n",
    "# Determine the proportion of men who survived\n",
    "proportion_men_survived = float(len(men[men.Survived == 1])) / len(men)\n",
    "print 'The proportion of men who survived is %s.' % proportion_men_survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that women were MUCH more likely to survive, and we _could_ just say that our model is:\n",
    "    - if female, survived = 1\n",
    "    - if male, survived = 0\n",
    "    \n",
    "But let's use the Python library Scikit-learn to see if we can do a little better than that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# But first, we need to do some more wrangling. 'Sex' is stored as a text value. We \n",
    "# should convert (or 'map') it into numeric binaries so it will be ready for scikit-learn.\n",
    "df['Sex'] = df['Sex'].map({'male': 0,'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scikit-learn won't be tolerant of the missing values. In the last class, we dropped\n",
    "# the 'Ticket' column. Let's also drop the 'Cabin' and 'Embarked' columns\n",
    "df = df.drop(['Cabin'], axis=1)\n",
    "df = df.drop(['Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's also drop the 'Name' column for now (though I can think of some interesting \n",
    "# data that might be embedded in those salutations...)\n",
    "df = df.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've got a table of purely numeric data with no null values. We're ready to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-learn\n",
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mlchang/titanic/logistic-model-using-scikit-learn/run/91385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression mathematically calculates the decision boundary between death and survival. This way it can figure out the best cutoff to choose that most accurately represents the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Next we want to divide our dataframe columns into signals and labels. The signals \n",
    "# are the information our machine learning algorith will use to make predictions.\n",
    "# The labels are the \"right answers\". In this case, that will be the boolean 'Survived'.\n",
    "signals = df[['Survived','Sex','Age']].values\n",
    "labels = df['Survived'].values\n",
    "# fit OLS regression \n",
    "est = LinearRegression(fit_intercept=True, normalize=True)\n",
    "est.fit(signals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our machine learning algorithm to look for patterns and break our dataset into pieces,\n",
    "so we need to pick a classifier. Let's begin with a random forest, which is a 'meta estimator'. \n",
    "It will fit a number of decision trees (we'll have to tell it how many) on various sub-samples \n",
    "of the dataset. Then it will use averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "Read more about Random Forests here:    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll select 50 trees and opt for 'out-of-bag' samples to estimate the generalization error.\n",
    "clf = RandomForestClassifier(n_estimators=50, oob_score=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sub-samples should we specify?     \n",
    "\n",
    "The training samples are constructed by splitting our original dataset into more than one part. But what if certain chunks of our data have more variance than others? We want to ensure that our model is accurate regardless of the particular way the data are divided up.    \n",
    "\n",
    "This is called __cross-validation__.\n",
    "\n",
    "More on cross-validation tools inside Scikit-learn here:    \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's divide the data into 12 parts. Because that's Ben's favorite number.\n",
    "test_size_percent = 0.083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, n_estimators=50, n_jobs=1, oob_score=True,\n",
       "            random_state=None, verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next split up the data with the 'train test split' method in the Cross Validation module\n",
    "train_signals, test_signals, train_labels, test_labels = train_test_split(signals, labels, test_size=test_size_percent)\n",
    "\n",
    "# ...and then run the 'fit' method to build a forest of trees\n",
    "clf.fit(train_signals, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use the Random Forest 'predict probabilities' method on our test signals:\n",
    "predictions = clf.predict_proba(test_signals)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://github.com/rebeccabilbro/pyconuk-introtutorial/blob/master/notebooks/Section%202-2%20-%20SVM%20with%20Parameter%20Tuning.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
